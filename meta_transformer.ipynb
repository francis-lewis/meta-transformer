{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bbfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sairg_utils import launch, \\\n",
    "                        get_data_loaders, \\\n",
    "                        train, \\\n",
    "                        test, \\\n",
    "                        set_random_seeds, \\\n",
    "                        define_finetune_model, \\\n",
    "                        train_process, \\\n",
    "                        builtin_model_initializer, \\\n",
    "                        get_model\n",
    "set_random_seeds()\n",
    "from meta_transformer_vanilla import MetaTransformer\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "EXPERIMENT_ROOT = os.path.expanduser(\"~/Developer/experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1c412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_weights = copy.deepcopy(torchvision.models.ResNet18_Weights)\n",
    "dataset = torchvision.datasets.CIFAR10\n",
    "transforms = base_model_weights.DEFAULT.transforms()\n",
    "\n",
    "model_class = torchvision.models.resnet18\n",
    "model_params = {'pos_params': [],\n",
    "                'key_params': {'weights': base_model_weights},}\n",
    "finetune_params = {'num_classes': 10,\n",
    "                   'head_layer_name': 'fc'}\n",
    "model_params['finetune_params'] = finetune_params\n",
    "loss_fn_class = torch.nn.CrossEntropyLoss\n",
    "optimizer_class = torch.optim.Adam\n",
    "optimizer_params = {'lr': 1e-3}\n",
    "checkpoint_dir = os.path.join(EXPERIMENT_ROOT, \"model_ckpts\")\n",
    "checkpoint_prefix = \"resnet18_cifar10\"\n",
    "\n",
    "training_args = {'dataset': dataset,\n",
    "                 'transforms': transforms,\n",
    "                 'num_epochs': 1,\n",
    "                 'batch_size': 64,\n",
    "                 'model_class': model_class,\n",
    "                 'model_params': model_params,\n",
    "                 'model_initializer': builtin_model_initializer,\n",
    "                 'loss_fn_class': loss_fn_class,\n",
    "                 'optimizer_class': optimizer_class,\n",
    "                 'optimizer_params': optimizer_params,\n",
    "                 'checkpoint_dir': checkpoint_dir,\n",
    "                 'checkpoint_prefix': checkpoint_prefix\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499f2038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       " ),\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f34542bed90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f33a57f4610>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(training_args)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4fe730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train process rank 0\n",
      "Running DDP on rank 0\n",
      "Train process rank 1\n",
      "Running DDP on rank 1\n",
      "[1,    78] loss: 1.527\n",
      "[1,    78] loss: 1.524\n",
      "[1,   156] loss: 0.978\n",
      "[1,   156] loss: 1.006\n",
      "[1,   234] loss: 0.870\n",
      "[1,   234] loss: 0.853\n",
      "[1,   312] loss: 0.801\n",
      "[1,   312] loss: 0.816\n",
      "[1,   390] loss: 0.790\n",
      "[1,   390] loss: 0.770\n",
      "Accuracy after epoch 1: 75.37 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.73158383369446"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tok = time.time()\n",
    "# launch(training_args, num_proc=2)\n",
    "# tik = time.time()\n",
    "# tik - tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d6cddd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_net_weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "# base_net = torchvision.models.resnet18(weights=base_net_weights)\n",
    "# module_list = [k for k, v in base_net.named_modules() if 'layer' in k and '.' not in k]\n",
    "# # module_list = [k for k, v in base_net.named_modules() if 'bn' in k]\n",
    "# module_list += ['fc']\n",
    "# print(len(module_list))\n",
    "# module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba4d11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(base_net_weights)\n",
    "# base_net_weights == torchvision.models.ResNet18_Weights.DEFAULT\n",
    "# type(base_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe4712e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_net_weights = torchvision.models.ViT_B_32_Weights.DEFAULT\n",
    "# base_net = torchvision.models.vit_b_32(weights=base_net_weights)\n",
    "# # [k for k, v in base_net.named_modules() if 'encoder_layer' in k and len(k.split('.')) < 4]\n",
    "# # [k for k, v in base_net.named_modules()]\n",
    "# dict(base_net.named_modules())['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b1fa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = torchvision.datasets.CIFAR10\n",
    "# transform = base_net_weights.transforms()\n",
    "# train_loader, test_loader = get_data_loaders(dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb806af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(getattr(base_net, 'fc'))\n",
    "# base_net = define_finetune_model(base_net, 10, 'fc', finetune_base=False)\n",
    "# print(getattr(base_net, 'fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d7619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ckpt_dir = os.path.expanduser('~/Developer/experiments/meta-transformer/model_ckpts')\n",
    "# base_model_filename = 'resnet18_cifar10.pth'\n",
    "# base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "# if os.path.exists(base_model_path):\n",
    "#     base_net.load_state_dict(torch.load(base_model_path))\n",
    "# else:\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(base_net.parameters(), lr=1e-3)\n",
    "#     base_net.to(device)\n",
    "#     tik = time.time()\n",
    "#     loss = train(base_net, loss_fn, optimizer, device, train_loader)\n",
    "#     tok = time.time()\n",
    "#     print(loss)\n",
    "#     print(tok - tik)\n",
    "#     torch.save(base_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2861df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_net.to(device)\n",
    "# acc = test(base_net, device, test_loader)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ab8a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images, _ = iter(train_loader).next()\n",
    "# images = images.to(device)\n",
    "# num_layers = 2\n",
    "# meta_net = MetaTransformer(base_net, module_list, images, num_transformer_layers=num_layers)\n",
    "# meta_net.to(device)\n",
    "# meta_net(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c19dbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_reload = True\n",
    "# base_model_filename = 'meta_transformer_resnet18_cifar10.pth'\n",
    "# base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "# if do_reload and os.path.exists(base_model_path):\n",
    "#     meta_net.load_state_dict(torch.load(base_model_path))\n",
    "# else:\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(meta_net.parameters(), lr=1e-4)\n",
    "#     meta_net.to(device)\n",
    "#     tik = time.time()\n",
    "#     loss = train(meta_net, loss_fn, optimizer, device, train_loader)\n",
    "#     tok = time.time()\n",
    "#     print(loss)\n",
    "#     print(tok - tik)\n",
    "#     torch.save(meta_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af4eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.to(device)\n",
    "# acc = test(meta_net, device, test_loader)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3432139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.eval()\n",
    "# meta_net(images)\n",
    "\n",
    "# acts = meta_net._activations['fc']\n",
    "# vals, inds = torch.max(acts, 1)\n",
    "# vals = torch.unsqueeze(vals, 1)\n",
    "# inds = torch.unsqueeze(inds, 1).repeat((1, 10))\n",
    "# src = torch.tensor(range(100)).reshape((10, 10))\n",
    "# src = src.unsqueeze(0).repeat((64, 1, 1))\n",
    "# torch.scatter(torch.zeros_like(acts), 1, inds, vals)\n",
    "\n",
    "# print(acts.shape)\n",
    "# res = acts[inds == 6].reshape((-1, 10))\n",
    "# print(res.shape)\n",
    "# # print(acts.unsqueeze(-1)[inds == 6].shape)\n",
    "# src = torch.tensor(range(10), dtype=acts.dtype, device=acts.device).repeat((6))\n",
    "# print(src.shape)\n",
    "# acts[inds == 6] = src\n",
    "# print(acts.shape)\n",
    "# acts\n",
    "# vals.squeeze().shape\n",
    "# print(f\"{acts.shape}, {inds.shape}, {vals.shape}\")\n",
    "\n",
    "# a = torch.reshape(torch.tensor(range(40)), (4, 10))\n",
    "# inds = torch.tensor([[2, 3], [6, 7], [0, 1], [4, 5]])\n",
    "# inds == 2\n",
    "# b = torch.gather(a, 1, inds)\n",
    "# b[inds == 2]\n",
    "\n",
    "# inds = inds.repeat((1, output.shape[-1]))\n",
    "# output = torch.reshape(output[inds == 19], (-1, output.shape[-1]))\n",
    "# avgs = torch.mean(output, 0, keepdim=True)\n",
    "# avgs.shape\n",
    "# output.shape\n",
    "\n",
    "# meta_net._activations['fc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78bc5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6682daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# tik = time.time()\n",
    "# launch(num_epochs=num_epochs, num_proc=2)\n",
    "# tok = time.time()\n",
    "# tok - tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38780db1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # vit_net = SimpleViT(\n",
    " #     image_size = 32,\n",
    " #     patch_size = 8,\n",
    " #     num_classes = len(classes),\n",
    " #     dim = 1024,\n",
    " #     depth = 6,\n",
    " #     heads = 16,\n",
    " #     mlp_dim = 2048\n",
    " # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
