{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sairg_utils import launch, get_data_loaders, train, test, set_random_seeds, define_finetune_model\n",
    "set_random_seeds()\n",
    "from meta_transformer import MetaTransformer\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6cddd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_net_weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "base_net = torchvision.models.resnet18(weights=base_net_weights)\n",
    "module_list = [k for k, v in base_net.named_modules() if 'layer' in k and '.' not in k]\n",
    "# module_list = [k for k, v in base_net.named_modules() if 'bn' in k]\n",
    "module_list += ['fc']\n",
    "print(len(module_list))\n",
    "module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4712e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_net_weights = torchvision.models.ViT_B_32_Weights.DEFAULT\n",
    "# base_net = torchvision.models.vit_b_32(weights=base_net_weights)\n",
    "# # [k for k, v in base_net.named_modules() if 'encoder_layer' in k and len(k.split('.')) < 4]\n",
    "# # [k for k, v in base_net.named_modules()]\n",
    "# dict(base_net.named_modules())['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1fa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10\n",
    "transform = base_net_weights.transforms()\n",
    "train_loader, test_loader = get_data_loaders(dataset, transform)\n",
    "\n",
    "# im, labels = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb806af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(getattr(base_net, 'fc'))\n",
    "base_net = define_finetune_model(base_net, 10, 'fc', finetune_base=False)\n",
    "print(getattr(base_net, 'fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt_dir = os.path.expanduser('~/Developer/experiments/meta-transformer/model_ckpts')\n",
    "base_model_filename = 'resnet18_cifar10.pth'\n",
    "base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "if os.path.exists(base_model_path):\n",
    "    base_net.load_state_dict(torch.load(base_model_path))\n",
    "else:\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(base_net.parameters(), lr=1e-3)\n",
    "    base_net.to(device)\n",
    "    tik = time.time()\n",
    "    loss = train(base_net, loss_fn, optimizer, device, train_loader)\n",
    "    tok = time.time()\n",
    "    print(loss)\n",
    "    print(tok - tik)\n",
    "    torch.save(base_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net.to(device)\n",
    "acc = test(base_net, device, test_loader)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43029253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, _ = iter(train_loader).next()\n",
    "images = images.to(device)\n",
    "num_layers = 2\n",
    "meta_net = MetaTransformer(base_net, module_list, images, num_transformer_layers=num_layers)\n",
    "meta_net.to(device)\n",
    "meta_net(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19dbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_reload = True\n",
    "base_model_filename = 'meta_transformer_resnet18_cifar10.pth'\n",
    "base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "if do_reload and os.path.exists(base_model_path):\n",
    "    meta_net.load_state_dict(torch.load(base_model_path))\n",
    "else:\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(meta_net.parameters(), lr=1e-4)\n",
    "    meta_net.to(device)\n",
    "    tik = time.time()\n",
    "    loss = train(meta_net, loss_fn, optimizer, device, train_loader)\n",
    "    tok = time.time()\n",
    "    print(loss)\n",
    "    print(tok - tik)\n",
    "    torch.save(meta_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c36a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_net.to(device)\n",
    "acc = test(meta_net, device, test_loader)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# tik = time.time()\n",
    "# launch(num_epochs=num_epochs, num_proc=2)\n",
    "# tok = time.time()\n",
    "# tok - tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38780db1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # vit_net = SimpleViT(\n",
    " #     image_size = 32,\n",
    " #     patch_size = 8,\n",
    " #     num_classes = len(classes),\n",
    " #     dim = 1024,\n",
    " #     depth = 6,\n",
    " #     heads = 16,\n",
    " #     mlp_dim = 2048\n",
    " # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
