{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import sairg_utils\n",
    "\n",
    "sairg_utils.set_random_seeds()\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet base model using SAIRG infrastructure\n",
    "\n",
    "base_model_weights = 'torchvision.models.ResNet18_Weights'\n",
    "dataset = 'torchvision.datasets.CIFAR10'\n",
    "transforms = 'torchvision.models.ResNet18_Weights.DEFAULT.transforms'\n",
    "\n",
    "model_class = 'torchvision.models.resnet18'\n",
    "model_params = {'pos_params': [],\n",
    "                'key_params': {'weights': base_model_weights},}\n",
    "finetune_params = {'num_classes': 10,\n",
    "                   'head_layer_name': 'fc'}\n",
    "model_params['finetune_params'] = finetune_params\n",
    "model_initializer = 'sairg_utils.builtin_model_initializer'\n",
    "loss_fn_class = 'torch.nn.CrossEntropyLoss'\n",
    "optimizer_class = 'torch.optim.Adam'\n",
    "optimizer_params = {'lr': 1e-3}\n",
    "checkpoint_dir = os.path.join(os.getcwd(), \"model_ckpts\")\n",
    "checkpoint_prefix = \"resnet18_cifar10\"\n",
    "\n",
    "base_training_args = {'dataset': dataset,\n",
    "                     'transforms': transforms,\n",
    "                     'num_epochs': 10,\n",
    "                     'batch_size': 64,\n",
    "                     'model_class': model_class,\n",
    "                     'model_params': model_params,\n",
    "                     'model_initializer': model_initializer,\n",
    "                     'loss_fn_class': loss_fn_class,\n",
    "                     'optimizer_class': optimizer_class,\n",
    "                     'optimizer_params': optimizer_params,\n",
    "                     'checkpoint_dir': checkpoint_dir,\n",
    "                     'checkpoint_prefix': checkpoint_prefix\n",
    "                    }\n",
    "\n",
    "# sairg_utils.train_process(0, base_training_args)\n",
    "# base_model = sairg_utils.get_model(base_training_args, train=True)\n",
    "\n",
    "# train_loader, test_loader = get_data_loaders(dataset, transforms)\n",
    "\n",
    "# base_model.to(device)\n",
    "# acc = test(base_model, device, test_loader)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MetaNet\n",
    "# 725s, 86%, ZeRO + 2 layers\n",
    "# 191s, 85%, 1 thr + 2 layers\n",
    "\n",
    "dataset = 'torchvision.datasets.CIFAR10'\n",
    "transforms = 'torchvision.models.ResNet18_Weights.DEFAULT.transforms'\n",
    "\n",
    "model_class = 'meta_transformer_vanilla.MetaTransformer'\n",
    "base_model = sairg_utils.get_model(base_training_args)\n",
    "dataset_class = sairg_utils.get_class_by_path(dataset)\n",
    "transform_class = sairg_utils.get_class_by_path(transforms)()\n",
    "train_loader, test_loader = sairg_utils.get_data_loaders(dataset_class, transform_class)\n",
    "layer_names = [k for k, v in base_model.named_modules() if 'layer' in k and '.' not in k] + ['fc']\n",
    "del base_model\n",
    "input_batch, _ = iter(train_loader).next()\n",
    "base_model_checkpoint_path = os.path.join(base_training_args['checkpoint_dir'],\n",
    "                                          base_training_args['checkpoint_prefix'])\n",
    "model_params = {'layer_names': layer_names,\n",
    "                'input_batch': input_batch.shape,\n",
    "                'base_training_args': base_training_args,\n",
    "                'kwargs': {'num_transformer_layers': 2}}\n",
    "model_initializer = 'meta_transformer_vanilla.metatransformer_model_initializer'\n",
    "loss_fn_class = 'torch.nn.CrossEntropyLoss'\n",
    "optimizer_class = 'torch.optim.Adam'\n",
    "optimizer_params = {'lr': 1e-4}\n",
    "checkpoint_dir = os.path.join(os.getcwd(), \"model_ckpts\")\n",
    "checkpoint_prefix = \"meta_transformer_resnet18_cifar10\"\n",
    "\n",
    "meta_training_args = {'dataset': dataset,\n",
    "                     'transforms': transforms,\n",
    "                     'num_epochs': 1,\n",
    "                     'batch_size': 64,\n",
    "                     'model_class': model_class,\n",
    "                     'model_params': model_params,\n",
    "                     'model_initializer': model_initializer,\n",
    "                     'loss_fn_class': loss_fn_class,\n",
    "                     'optimizer_class': optimizer_class,\n",
    "                     'optimizer_params': optimizer_params,\n",
    "                     'checkpoint_dir': checkpoint_dir,\n",
    "                     'checkpoint_prefix': checkpoint_prefix\n",
    "                    }\n",
    "# meta_model = sairg_utils.get_model(meta_training_args, train=True, force=True)\n",
    "meta_model = sairg_utils.get_model(meta_training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520411f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tok = time.time()\n",
    "# launch(meta_training_args, num_proc=2)\n",
    "# train_process(0, meta_training_args)\n",
    "tik = time.time()\n",
    "tik - tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eab5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6cddd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_net_weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "# base_net = torchvision.models.resnet18(weights=base_net_weights)\n",
    "# module_list = [k for k, v in base_net.named_modules() if 'layer' in k and '.' not in k]\n",
    "# # module_list = [k for k, v in base_net.named_modules() if 'bn' in k]\n",
    "# module_list += ['fc']\n",
    "# print(len(module_list))\n",
    "# module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(base_net_weights)\n",
    "# base_net_weights == torchvision.models.ResNet18_Weights.DEFAULT\n",
    "# type(base_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4712e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_net_weights = torchvision.models.ViT_B_32_Weights.DEFAULT\n",
    "# base_net = torchvision.models.vit_b_32(weights=base_net_weights)\n",
    "# # [k for k, v in base_net.named_modules() if 'encoder_layer' in k and len(k.split('.')) < 4]\n",
    "# # [k for k, v in base_net.named_modules()]\n",
    "# dict(base_net.named_modules())['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1fa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = torchvision.datasets.CIFAR10\n",
    "# transform = base_net_weights.transforms()\n",
    "# train_loader, test_loader = get_data_loaders(dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb806af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(getattr(base_net, 'fc'))\n",
    "# base_net = define_finetune_model(base_net, 10, 'fc', finetune_base=False)\n",
    "# print(getattr(base_net, 'fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ckpt_dir = os.path.expanduser('~/Developer/experiments/meta-transformer/model_ckpts')\n",
    "# base_model_filename = 'resnet18_cifar10.pth'\n",
    "# base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "# if os.path.exists(base_model_path):\n",
    "#     base_net.load_state_dict(torch.load(base_model_path))\n",
    "# else:\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(base_net.parameters(), lr=1e-3)\n",
    "#     base_net.to(device)\n",
    "#     tik = time.time()\n",
    "#     loss = train(base_net, loss_fn, optimizer, device, train_loader)\n",
    "#     tok = time.time()\n",
    "#     print(loss)\n",
    "#     print(tok - tik)\n",
    "#     torch.save(base_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_net.to(device)\n",
    "# acc = test(base_net, device, test_loader)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab8a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images, _ = iter(train_loader).next()\n",
    "# images = images.to(device)\n",
    "# num_layers = 2\n",
    "# meta_net = MetaTransformer(base_net, module_list, images, num_transformer_layers=num_layers)\n",
    "# meta_net.to(device)\n",
    "# meta_net(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19dbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_reload = True\n",
    "# base_model_filename = 'meta_transformer_resnet18_cifar10.pth'\n",
    "# base_model_path = os.path.join(model_ckpt_dir, base_model_filename)\n",
    "# if do_reload and os.path.exists(base_model_path):\n",
    "#     meta_net.load_state_dict(torch.load(base_model_path))\n",
    "# else:\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(meta_net.parameters(), lr=1e-4)\n",
    "#     meta_net.to(device)\n",
    "#     tik = time.time()\n",
    "#     loss = train(meta_net, loss_fn, optimizer, device, train_loader)\n",
    "#     tok = time.time()\n",
    "#     print(loss)\n",
    "#     print(tok - tik)\n",
    "#     torch.save(meta_net.state_dict(), base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.to(device)\n",
    "# acc = test(meta_net, device, test_loader)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3432139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.eval()\n",
    "# meta_net(images)\n",
    "\n",
    "# acts = meta_net._activations['fc']\n",
    "# vals, inds = torch.max(acts, 1)\n",
    "# vals = torch.unsqueeze(vals, 1)\n",
    "# inds = torch.unsqueeze(inds, 1).repeat((1, 10))\n",
    "# src = torch.tensor(range(100)).reshape((10, 10))\n",
    "# src = src.unsqueeze(0).repeat((64, 1, 1))\n",
    "# torch.scatter(torch.zeros_like(acts), 1, inds, vals)\n",
    "\n",
    "# print(acts.shape)\n",
    "# res = acts[inds == 6].reshape((-1, 10))\n",
    "# print(res.shape)\n",
    "# # print(acts.unsqueeze(-1)[inds == 6].shape)\n",
    "# src = torch.tensor(range(10), dtype=acts.dtype, device=acts.device).repeat((6))\n",
    "# print(src.shape)\n",
    "# acts[inds == 6] = src\n",
    "# print(acts.shape)\n",
    "# acts\n",
    "# vals.squeeze().shape\n",
    "# print(f\"{acts.shape}, {inds.shape}, {vals.shape}\")\n",
    "\n",
    "# a = torch.reshape(torch.tensor(range(40)), (4, 10))\n",
    "# inds = torch.tensor([[2, 3], [6, 7], [0, 1], [4, 5]])\n",
    "# inds == 2\n",
    "# b = torch.gather(a, 1, inds)\n",
    "# b[inds == 2]\n",
    "\n",
    "# inds = inds.repeat((1, output.shape[-1]))\n",
    "# output = torch.reshape(output[inds == 19], (-1, output.shape[-1]))\n",
    "# avgs = torch.mean(output, 0, keepdim=True)\n",
    "# avgs.shape\n",
    "# output.shape\n",
    "\n",
    "# meta_net._activations['fc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_net.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# tik = time.time()\n",
    "# launch(num_epochs=num_epochs, num_proc=2)\n",
    "# tok = time.time()\n",
    "# tok - tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38780db1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # vit_net = SimpleViT(\n",
    " #     image_size = 32,\n",
    " #     patch_size = 8,\n",
    " #     num_classes = len(classes),\n",
    " #     dim = 1024,\n",
    " #     depth = 6,\n",
    " #     heads = 16,\n",
    " #     mlp_dim = 2048\n",
    " # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
